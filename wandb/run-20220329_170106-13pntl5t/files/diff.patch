diff --git a/cnn_config.json b/cnn_config.json
index 83f1667..5294792 100644
--- a/cnn_config.json
+++ b/cnn_config.json
@@ -5,12 +5,13 @@
         "lr_decay_factor": 0,
         "batch_size": 32,
         "data_split": 0.8,
-        "data_augmentation": "False"
+        "data_augmentation": "False",
+        "dropout": 0.2
     },
 
     "architecture_params":{
-        "num_cnn_layers": 3, 
-        "kernel_size": 5,
+        "num_cnn_layers": 5, 
+        "kernel_size": 3,
         "num_filters": [16, 32, 64, 128, 256],
         "pool_kernel": 2,
         "optimiser": "adam",
diff --git a/cnn_image_classifier.py b/cnn_image_classifier.py
index 0ee6068..f77f583 100644
--- a/cnn_image_classifier.py
+++ b/cnn_image_classifier.py
@@ -9,6 +9,7 @@ import numpy as np
 import json
 import sys
 import time
+from wandb.keras import WandbCallback
 import os
 
 def read_config(json_path):
@@ -63,6 +64,7 @@ if __name__ == "__main__":
     batch_size = json_dict["training_params"]["batch_size"]
     data_split = json_dict["training_params"]["data_split"]
     data_augmentation = json_dict["training_params"]["data_augmentation"]
+    dropout = json_dict["training_params"]["dropout"]
 
     num_cnn_layers = json_dict["architecture_params"]["num_cnn_layers"]
     num_filters = json_dict["architecture_params"]["num_filters"]
@@ -131,8 +133,53 @@ if __name__ == "__main__":
 
     model = cnn_model(num_cnn_layers, num_filters, kernel_size, activation_cnn, activation_fc, dense_neurons, img_size, pool_kernel)
 
+    sweep_config = {
+    "name": "Bayesian Sweep",
+    "method": "bayes",
+    "metric":{
+        "name": "val_accuracy",
+        "goal": "maximize"
+        },
+    'early_terminate': {
+        'type':'hyperband',
+        'min_iter': [3],
+        's': [2]
+        },
+    "parameters":{
+        "activation_cnn": {
+            "values": ["relu"]
+            },
+        "batch_size":{
+            "values": [32, 64, 128]
+            },
+        "data_augmentation": {
+            "values": ["True", "False"]
+            },
+        "epochs":{
+            "values": [20, 30, 40, 50, 60]
+            },
+        "learning_rate": {
+            "values": [0.0001, 0.005, 0.001]
+            },
+        "num_filters": {
+            "values": [
+                [16, 32, 64, 128, 256],
+                [32, 64, 128, 256, 512],
+                [32, 32, 32, 32, 32],
+                [512, 256, 128, 64, 32],
+                ]
+            }
+        }
+    }
+
+    sweep_id = wandb.sweep(sweep_config,project='CS6910-Assignment2', entity='anuj-sougat')
+
     start_time = time.time()
 
+    wandb.init(project = 'CS6910-Assignment2-CNNs', config = json_dict, entity='anuj-sougat')
+    CONFIG = wandb.config
+    wandb.run.name = "CNN2_" + str(CONFIG.architecture_params.num_cnn_layers) + "_dn_" + str(CONFIG.architecture_params.dense_neurons) + "_opt_" + CONFIG.architecture_params.optimiser + "_dro_" + str(CONFIG.training_params.dropout) + "_bs_" + str(CONFIG.training_params.batch_size) + "_fd_" + str(CONFIG.architecture_params.num_filters)
+
     model.compile(
         optimizer= "adam",
         loss = tf.keras.losses.CategoricalCrossentropy(from_logits= True),
@@ -146,6 +193,8 @@ if __name__ == "__main__":
         validation_steps = validation_generator.samples//batch_size,
         epochs = epochs
     )
+    model.save(".\\TrainedModel\\" + wandb.run.name)
+    wandb.finish()
 
     end_time = time.time()
 
